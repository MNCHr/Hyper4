CLEAN SLATE DESIGN

Ultimately we need the offsets for any source P4 program's fields represented in HP4's extracted.data field.  In support of this goal we need to ensure that the final time HP4 exits the setup control function, it has identified the path taken through the parser, corresponding to the parse control state.

OBJECTIVE 1: generate tset_control table entries
(Later objectives will handle tset_inspect_XX_YY entries and other tables in setup.p4.)

HP4's task is to apply tset_control for every pc.state to determine whether to extract more, inspect extracted bytes, or proceed to ingress.

A pc.state corresponds to a path segment in the parse tree of the source P4.  A path segment starts at 'start' or immediately following a conditional jump (from a select statement).  It terminates either at an unconditional jump to ingress, or at a conditional jump (i.e., select statement).  Note a pc.state is not the same thing as a parse_state (HLIR's term for a parse function in the source P4 program).

We refer to the jump to ingress (action: PROCEED) or to the select statement (action: INSPECT_XX_YY) as the path segment terminator.

So pc.state == 0 corresponds to the initial state of HP4 after a packet has been received.  We can reserve pc.state == 1 to the state of HP4 when prepared to carry out the inital path segment terminator.  Whether the action in tset_control [action] [program ID] 0 => [numbytes | next_action] 1 is extract_more or set_next_action, the action's state parameter should always be 1.

The number of pc.states should be upper bounded by 1 + the total number of entries across all select statements.

Remember that the tset_inspect_XX_YY table handling the select statement is responsible for extracting more bytes and updating the pc.state, so that by the time HP4 applies tset_control again, pc.state will be updated and enough bytes will have been extracted to handle the next path segment terminator.

action set_next_action(next_action, state) {
  modify_field(parse_ctrl.next_action, next_action);
  modify_field(parse_ctrl.state, state);
}

action extract_more(numbytes, state) {
  modify_field(parse_ctrl.numbytes, numbytes);
  modify_field(parse_ctrl.next_action, EXTRACT_MORE);
  modify_field(parse_ctrl.state, state);
  resubmit(fl_extract_more);
}

table tset_control {
  reads {
    meta_ctrl.program : exact;
    parse_ctrl.numbytes : exact;
    parse_ctrl.state : exact;
  }
  actions {
    set_next_action;
    set_next_action_chg_program;
    extract_more;
    extract_more_chg_program;
  }
}

Ignore set_next_action_chg_program and extract_more_chg_program for now.

pc_bits_extracted (dictionary):
- key: (integer) pc.state
- value: (integer) number of bytes we can assume have been extracted once we are in the pc.state

field_offsets (dictionary):
- key: (integer) pc.state
- value: (integer) offset

There is only one case where the tset_control entry will have extract_more as the action: pc.state is 0 and the number of bytes extracted prior to the first path segment terminator is more than SEB.

We have bits_extracted[0] = args.SEB, always.  HP4C traverses the parse tree until the first terminator, having populated bits_needed_total such that we have an entry for the key consisting of the terminator's parse_state and all preceding parse_states.  Then HP4C can determine the first tset_control entry to issue: extract_more or set_next_action (for a PROCEED or INSPECT_XX_YY as appropriate).

Objective 1 Algorithm: Go through the parse tree of the source P4 and identify all path segments, i.e., pc.states, their byte requirements, and their terminators.  Each extract statement should update field_offsets and bits_extracted.  For conditional jump terminators, use field_offsets to identify the byte range to inspect to properly handle the select statement.  Also for conditional jump terminators, look for the use of 'current' and update bits_extracted accordingly.  Prior to recursing for each condition of a conditional jump terminator, update the current pc.state, and set bits_extracted to that of the previous pc.state minus any bits required by 'current'.

OBJECTIVE 2: generate tset_inspect_XX_YY entries

In most cases, tset_inspect_XX_YY matches will trigger a set_next_action: PROCEED (direct jump to ingress) or an extract_more (next parse_state requires more bytes than what have been extracted so far).  The exception is a direct jump to another parse_state that does not extract any additional bytes nor employ 'current' beyond what has been extracted, in which case the action is determined by the terminator of the next parse_state.

We need a tset_inspect_XX_YY entry for each selectopt in each conditional return statement.

Challenges:
- identifying next pc_state
  - take advantage of walk_parse_tree that already does some handling for each 'selectopt' in the conditional return statement
- [DONE] producing the ternary match strings
  - take advantage of process_parse_state that already does some handling for each 'criteria' for the conditional return statement

action set_next_action(next_action, state) {
  modify_field(parse_ctrl.next_action, next_action);
  modify_field(parse_ctrl.state, state);
}

action extract_more(numbytes, state) {
  modify_field(parse_ctrl.numbytes, numbytes);
  modify_field(parse_ctrl.next_action, EXTRACT_MORE);
  modify_field(parse_ctrl.state, state);
  resubmit(fl_extract_more);
}

table tset_inspect_XX_YY {
  reads {
    meta_ctrl.program : exact;
    parse_ctrl.state: exact;
    ext[XX].data : ternary;
    // ...
    ext[YY].data : ternary;
  }
  actions {
    set_next_action;
    set_next_action_chg_program;
    extract_more;
    extract_more_chg_program;
  }
}

Ignore set_next_action_chg_program and extract_more_chg_program for now.

next_pc_states (dictionary):
- key: (integer) pc_state
- val: [pc_state, pc_state, ...]

tics_match_offsets (dictionary):
- key: (integer) pc_state
- val: [(offset, width), (offset, width), ...]
- populated: process_parse_state (within 'for criteria in parse_state.return_statement[1]:' block)

tics_table_names (dictionary):
- key: (integer) pc_state
- val: (string) specific instance of tset_inspect_XX_YY
- populated: process_parse_state (where pc_action is determined)

tics (class):
- instance created: walk_parse_tree (within 'for selectopt in parse_state.return_statement[2]:' block)
- (integer) current pc_state
  - use curr_pc_state
- (string) table
  - use tics_table_name[curr_pc_state]
- (string) match
  - create using tics_match_offsets[curr_pc_state] and selectopt
- (string) action
  - DELAY filling this in until parse tree has been walked.  THEN either set_next_action / [PROCEED] (in the case of a direct jump to ingress) or compare pc_bits_extracted (in the case of a jump to another parse_state) for current vs next state; if less than, extract_more; otherwise, use pc_action[next_pc_state]
- (integer) next_pc_state
- (string) next_parse_state

tics_list (list)
- populated: walk_parse_tree (after each instance of tics created)

We also need to generate the default entry, which will use match string consisting of a series of '0&&&0' values.  This can then be handled like any other tics, where the action is determined after the parse tree has been walked and depends on the next_parse_state and possibly pc_bits_extracted comparison.

Objective 2 Algorithm: Augment algorithm for objective 1:  To walk the parse tree, we are already collecting next parse_states identified by the selectopts present where the current parse_state ends in a conditional return statement.  Each such parse_state is the start (or, in most cases, the entirety) of a pc_state.  So we will make the association explicit at the time the next parse_state is collected.  This handles the second action parameter for each entry.

OBJECTIVE 3: generate tset_pipeline entries

Two subtasks are associated with this objective.  1) Determine the match type for the first table in the ingress pipeline so we can set the tableID correctly.  2) Set extracted.validbits to correctly reflect which headers are present in which order in the parsed representation.

First task is trivial if we assume that there can be only one entry point for the ingress pipeline, which by convention is always called 'ingress'.  (The compiler allows us to easily bypass this restriction but we will assume it holds for now.)

The second task is more complicated but shouldn't be too bad.  We can look at every pc_state that points at ingress and the ordered set of extract statements leading up to it.  Then we look at all of these ordered sets together one element at a time.  What is the set of unique header types covering the first elements?  The size of this set determines how many bits are required in extracted.validbits for the first element, with each bit corresponding to one of the header types.  This is not a very efficient method spacewise, but computation-wise is amenable to bitmasking to check for presence of a header in the parsed representation.

We need an entry for every pc_state that points at ingress.  Conveniently we have h.p4_ingress_ptr, a dictionary with the first table in the ingress pipeline as the key and the set of parse_states that include jumps to it as the value.  But remember that we may have multiple pc_states for each parse_state, so we need some help - we can collect the pc_states associated with every parse_state, for example.

Starting to think we need a pc_state class:
- ID (int, used in table entries)
- parse_state
- list of preceding parse_states

OK maybe not a class but rather a couple of dictionaries.

And in HP4C we could have a dictionary ps_to_pc where parse_state is the key and a list of pc_states is the value.

With the current and preceding parse_states we could accomplish task #2.

OBJECTIVE 4: generate template entries for each tX_extracted_exact tables

Requirements:
- table name
- action: 'init_program_state'
- match_params:
  - '[program ID]'
  - template for value string representing 100B: '[val]'
  - mask string representing field location within extracted.data (100B)
- action_params:
  - action_ID: retrieve from action_ID[action]
  - match_ID: unique # for every entry
  - next_table: nt = curr_table.next_[action], then table_to_trep[nt].stage
  - primitive: primitive_ID[action.call_sequence[0][0].name]

action init_program_state(action_ID, match_ID, next_table, primitive, primitive_subtype) {
  modify_field(meta_primitive_state.action_ID, action_ID);
  modify_field(meta_primitive_state.match_ID, match_ID);
  modify_field(meta_primitive_state.primitive_index, 1);
  modify_field(meta_ctrl.next_table, next_table);
  modify_field(meta_primitive_state.primitive, primitive);
  modify_field(meta_primitive_state.subtype, primitive_subtype);
  modify_field(meta_ctrl.stage_state, CONTINUE);
}

[+ sloop +]
table t[+X+]_extracted_exact {
  reads {
    meta_ctrl.program : exact;
    extracted.data : ternary;
  }
  actions {
    init_program_state;
  }
}

Need to navigate the nodes of the ingress pipeline and figure out the mapping
of each table application to a unique stage.  Specifically, we need to populate the table_to_trep dictionary (table is the key, Table_Rep is the value).

Start with h.p4_ingress_ptr.keys()[0], the first table in the ingress pipeline.  Do a depth-first search from there, using the current table's next_ dictionary to navigate the branches according to the action invoked in the current table.  That is, for the next_ dictionary, we have a key for every possible action, and the value is the next table to be invoked.

The mask string:  Need '0x' and 200 characters following, two for every byte.  First we get the offset via field_offsets[str(field)].  Divide offset by 8 to get the number of leading '00s' and append these to the string mp we are building.

Now if offset % 8 == 0 and field.width % 8 == 0, the task is simple: for field.width / 8, append '00'.  Otherwise we need to do a bit more work.

Algorithm:
  We start with bits_left = field.width bits to represent.  Then loop until bits_left == 0:

  Set curr_byte to 0 and set bit to 0b10000000.

  In the current byte, there will be some offset % 8 leading 0 bits.  Shift bit right by this many.  Next step depends on whether bits_left >= 8 - (offset % 8); if so, we then have 8 - (offset % 8) 1 bits (inner loop: curr_byte = curr_byte | bit; bit = bit >> 1) and set bits_left to bits_left - (8 - (offset % 8)).  If not, we have bits_left 1 bits (inner loop as in other case) and we set bits_left to 0.  We can calculate the hex representation of the resulting byte and append it to mp.  If we have bits_left > 0, we can then shift offset:
  offset = offset + 8 - (offset % 8).
Otherwise we are done.

OBJECTIVE 5: Handle entry templates for tX tables

The entry templates have to go somewhere.  They are incomplete and it makes no sense to try to load them into HyPer4.  Time to introduce the DPMU.  DPMU can be thought of as a function performed by the controller allowing the user to supply table_add commands formatted for the .source P4 program, which the DPMU then converts into HyPer4 commands by using the template.

To accomplish this, the simple version of the DPMU requires a file that includes the entry templates.  This file must include the association of each entry template with the corresponding table in the source program.  It must also include the association of each action_ID with the corresponding action in the source program.  Let's say the mode of use is to invoke the DPMU with such a file as a command line argument.  At the same time, we have to supply the actual program ID as a command line argument.  We finally need some way of associating each actual entry with a match ID (unique among all entries for the same table).  If DPMU were to continue running as a service in the background, we could use a set of counters, one counter for each table, tracking the number of entries the DPMU has produced for the table, and used as the match ID for the next table entry.  Otherwise, we can have the DPMU connect to the instance of HyPer4 and figure out the next match_ID to use based on how many entries are resident for the particular table.  Or we can have a separate file tracking this kind of state.  A command line flag would indicate that this file should be reset to initial values.

Let's see how each would look.

As a background service:
> ./dpmu_start template_file1 template_file2 ... template_filen -p [HyPer4 port]
[separate terminal]
> ./dpmu [-p [DPMU port]] [-t template file program ID]* [[-c single command] | [-f file with commands]]

As a static utility:
> ./dpmu -p [HyPer4 port] [-i] [-t template file] [-P program ID]* [[-c single command] | [-f file with commands]]

Static utility looks a little cleaner and is probably simpler to implement, too, but we likely want to get rid of the -i (initialize counters) option and have DPMU talk to HyPer4 to set the counters.  But the problem is we have to supply the template file every time?  How annoying is that?  Resolve this by maintaining a master template file, which is appended everytime dpmu is invoked with the -t option.  Repurpose -i for reinitializing the master template file.

- [ ] Establish template file format
- [ ] Connect to HyPer4, obtain list of all tX tables, and initialize counters
- [ ] Read template files and set up {src_table : template} as well as
      {src_action : action_ID} maps
- [ ] Accept single command and convert to entry ready for loading by HyPer4
- [ ] Accept file of multiple commands and convert to entries ready for loading
      by HyPer4 (through hp4l)

Template File Format:

Use JSON.  Each file has a collection of entry_template object declarations produced
by p4c-hp4 for a particular program.

entry_template:
- source program table name
- HyPer4 table name
- action (e.g., init_program_state)
- match field width
- mask
- source action name
- action ID
- next_table
- primitive
- primitive subtype

hp4c.py support:
- HP4_Match_Command
  Subclass of HP4_Command.
  __init__ parameters order: source_table, source_action, command, table,
                             action, mparams, aparams
- HP4C attribute: command_templates []

OBJECTIVE 6: generate entry templates for tX_stdmeta_* tables

We recognize the need for an entry in the gen_tX_templates method when we examine the source type and see that it is standard_metadata, generating an action of "set_meta_stdmeta".

Each table follows the same pattern:
- match parameter 1: [program ID]
- match parameter 2: a distinct field in standard_metadata
- action: init_program_state

Two challenges:
- identify the table
  Farther down in the gen_tX_templates method, we look at the field being matched on in order to produce the correct action parameter for the set_meta_stdmeta action.  We can similarly make use of the matched field earlier in the method where we set aname = 'set_meta_stdmeta'.  Or later when we test whether aname == 'init_program_state' - add another test for aname == 'set_meta_stdmeta'.
- collect the action parameters for init_program_state
  - actually this is pretty simple; just follow the pattern already established for other match types.

OBJECTIVE 7: generate entries for t_mod_XY

You know what would be great?  This would also support Objective 8: a data structure with {action_ID: ([stage a, stage b, ...], [(primitive type, primitive subtype), ...])}.  Not all primitives have meaningful subtypes but that's ok.  The point is the second member of the value tuple is the sequence of primitives for the action.  And with this data structure we can methodically go through every action_ID, every invokable stage, and every call in the call sequence, generating one table entry for that combination.  We know the table name from the stage, the primitive type, and the order of the call in the call list.

OBJECTIVE 8: generate entries for tstgXY_update_state

Every action is a collection of primitives, and we string the execution of them together with the use of the tstgXY_update_state tables.  We need to generate the entries for these tables.

For each action, we need to identify the possible stages in which it could be invoked.  Then, for every stage, we generate entries for tables tstgX1_update_state - tstgXn_update_state where n is the number of primitives and X is the stage.

[ ] Populate a data structure: {action_ID:[stage a, stage b, ...]} where the value is a list of stages from which the action could be invoked.
[ ] For each action:
      for each stage in the value list:
        generate one entry per primitive in the action:
          the table name is tstg[stage][primitive rank]_update_state
          the action is update_state (unless there are no more primitives following,
           in which case the action is finish_action)
          first match param: [program ID]
          second match param: action ID

OBJECTIVE 9: Handling modify_field([field], CONST) vs. modify_field([field], sig(x))

In get_prim_subtype we have decided to handle both of these as though the second parameter is a constant.  What are the implications?

The primitive subtype is set to 8, 9, or 10, depending on the type of the first parameter.

When we carry out the primitive, we apply t_mod_XY:

table t_mod_XY {
  reads {
    meta_ctrl.program : exact;
    meta_primitive_state.subtype : exact;
    meta_primitive_state.match_ID : exact;
  }
  actions {
    // ...
    mod_meta_const;
    mod_stdmeta_egressspec_const;
    mod_extracted_const;
    // ...
  }
}

The subtype and match_ID trigger the action that does the modify_field primitive.

The difference, really, is in the entry template that should be generated.  For a primitive in the source that uses a constant as the second parameter, the constant should be in the entry template, while when a signature_ref (action parameter reference) is used as the second parameter, we should have a fill-in-the-blank marker (e.g., [val]).

We need to tackle this when we get to the point of generating the t_mod_XY entry templates.  We do not have to worry about it for the HP4_Match_Command templates, though if we need to populate some data structure to support differentiation between actual constant and [val], get_prim_subtype might be the place to do it.

The JSON entry for the DPMU probably needs to include a flag for such entry templates.

Problem: have to generate a separate entry for every match_ID even though every other parameter is the same, when the src field of the modify_field call is a constant (when the src field of the call is an action parameter, we SHOULD have a separate entry for every match_ID)
Solution: use ternary matching on the match_ID instead.  That way, we can do 0&&&0 to render the match_ID irrelevant; else [val]&&&0b11111111111111111111111 or [val]&&&0x7FFFFF when it should be relevant.
